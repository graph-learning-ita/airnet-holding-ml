{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from dsc2024 import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 211679 entries, 504a62621cd231d6ab67e674ce538cd3 to c962a2267ae4fe0afa4c3542ebdbd403\n",
      "Data columns (total 41 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   prev_troca_cabeceira           211679 non-null  int64  \n",
      " 1   troca_cabeceira_hora_anterior  211679 non-null  int64  \n",
      " 2   destino_altitude               211679 non-null  int64  \n",
      " 3   destino_comprimento            211679 non-null  int64  \n",
      " 4   destino_largura                211679 non-null  int64  \n",
      " 5   metar_latitude                 211679 non-null  float64\n",
      " 6   metar_longitude                211679 non-null  float64\n",
      " 7   metar_elevation                211679 non-null  float64\n",
      " 8   metar_wind_direction           211679 non-null  float64\n",
      " 9   metar_wind_speed               211679 non-null  float64\n",
      " 10  metar_wind_gust                211679 non-null  float64\n",
      " 11  metar_visibility               211679 non-null  float64\n",
      " 12  metar_skylev1                  211679 non-null  float64\n",
      " 13  metar_skylev2                  211679 non-null  float64\n",
      " 14  metar_skylev3                  211679 non-null  float64\n",
      " 15  metar_skylev4                  211679 non-null  float64\n",
      " 16  metar_cloudcover               211679 non-null  float64\n",
      " 17  metar_temperature              211679 non-null  float64\n",
      " 18  metar_dewpoint                 211679 non-null  float64\n",
      " 19  metar_altimeter                211679 non-null  float64\n",
      " 20  metar_current_wx1_symbol       211679 non-null  float64\n",
      " 21  metar_current_wx2_symbol       211679 non-null  float64\n",
      " 22  metar_current_wx3_symbol       211679 non-null  float64\n",
      " 23  metaf_latitude                 211679 non-null  float64\n",
      " 24  metaf_longitude                211679 non-null  float64\n",
      " 25  metaf_elevation                211679 non-null  float64\n",
      " 26  metaf_wind_direction           211679 non-null  float64\n",
      " 27  metaf_wind_speed               211679 non-null  float64\n",
      " 28  metaf_wind_gust                211679 non-null  float64\n",
      " 29  metaf_visibility               211679 non-null  float64\n",
      " 30  metaf_skylev1                  211679 non-null  float64\n",
      " 31  metaf_skylev2                  211679 non-null  float64\n",
      " 32  metaf_skylev3                  211679 non-null  float64\n",
      " 33  metaf_skylev4                  211679 non-null  float64\n",
      " 34  metaf_cloudcover               211679 non-null  float64\n",
      " 35  metaf_temperature              211679 non-null  float64\n",
      " 36  metaf_dewpoint                 211679 non-null  float64\n",
      " 37  metaf_altimeter                211679 non-null  float64\n",
      " 38  metaf_current_wx1_symbol       211679 non-null  float64\n",
      " 39  metaf_current_wx2_symbol       211679 non-null  float64\n",
      " 40  metaf_current_wx3_symbol       211679 non-null  float64\n",
      "dtypes: float64(36), int64(5)\n",
      "memory usage: 67.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = datasets.get_train_dataset()\n",
    "df_features = df.select_dtypes(include='number').drop(\"espera\", axis=1)\n",
    "df_features.fillna(0, inplace=True)\n",
    "df_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:  Data(edge_index=[2, 211679], edge_attr=[211679, 41], y=[211679, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 122\u001b[0m\n\u001b[1;32m    120\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 122\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[13], line 61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, train_mask, optimizer, criterion)\u001b[0m\n\u001b[1;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: \u001b[39m\u001b[38;5;124m\"\u001b[39m, data)\n\u001b[0;32m---> 61\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Edge-level output\u001b[39;00m\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out[train_mask], data\u001b[38;5;241m.\u001b[39my[train_mask])\n\u001b[1;32m     64\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/home/lerax/Desktop/workspace/dsc2024/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/lerax/Desktop/workspace/dsc2024/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m, in \u001b[0;36mFlightGNNWithGAT.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     18\u001b[0m x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Apply GATConv layer\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/home/lerax/Desktop/workspace/dsc2024/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/lerax/Desktop/workspace/dsc2024/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/lerax/Desktop/workspace/dsc2024/.venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py:311\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    308\u001b[0m         x_dst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_dst(x)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, C)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Tuple of source and target node features:\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     x_src, x_dst \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x_src\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatic graphs not supported in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGATConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x_dst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "NUM_EDGE_FEATURES = len(df_features.columns)\n",
    "\n",
    "# GNN model with a single GATConv layer for binary classification\n",
    "class FlightGNNWithGAT(torch.nn.Module):\n",
    "    def __init__(self, num_features=1, hidden_size=32, target_size=1):\n",
    "        super(FlightGNNWithGAT, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_features = num_features\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # Single GATConv layer\n",
    "        self.conv = GATConv(self.num_features, self.hidden_size, edge_dim=NUM_EDGE_FEATURES)\n",
    "\n",
    "        # Linear layer for final edge-level classification output\n",
    "        self.edge_mlp = nn.Linear(2 * self.hidden_size + NUM_EDGE_FEATURES, self.target_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        # print(f\"DEBUG: x = {x}\")  # Debug node features\n",
    "        # print(f\"DEBUG: edge_index = {edge_index}\")  # Debug edge_index\n",
    "        # print(f\"DEBUG: edge_attr = {edge_attr}\")  # Debug edge attributes\n",
    "\n",
    "        # Apply GATConv layer\n",
    "        x = self.conv(x, edge_index, edge_attr=edge_attr)\n",
    "        #print(f\"DEBUG: after GATConv, x = {x}\")  # Check after GATConv\n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Concatenate node embeddings of the source and destination nodes of each edge, along with edge attributes\n",
    "        row, col = edge_index\n",
    "        #print(f\"DEBUG: row = {row}, col = {col}\")  # Check row and col indices\n",
    "\n",
    "        edge_rep = torch.cat([x[row], x[col], edge_attr], dim=1)\n",
    "\n",
    "        return torch.sigmoid(self.edge_mlp(edge_rep))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Probabilities\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.mean()\n",
    "\n",
    "def train_test_split_data(data, test_size=0.2):\n",
    "    num_edges = data.edge_index.shape[1]\n",
    "    edge_indices = list(range(num_edges))\n",
    "\n",
    "    train_indices, test_indices = train_test_split(edge_indices, test_size=test_size)\n",
    "\n",
    "    train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "\n",
    "    train_mask[train_indices] = True\n",
    "    test_mask[test_indices] = True\n",
    "\n",
    "    return train_mask, test_mask\n",
    "\n",
    "def train(model, data, train_mask, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"DEBUG: \", data)\n",
    "    out = model(data)  # Edge-level output\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data, test_mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        preds = (out[test_mask] > 0.5).float()\n",
    "\n",
    "        y_true = data.y[test_mask].numpy()\n",
    "        y_pred = preds.numpy()\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        return acc, precision, recall, f1, cm\n",
    "\n",
    "def prepare_data(df):\n",
    "    # Convert your DataFrame into PyG Data format\n",
    "    node_set = set(df['origem']).union(set(df['destino']))\n",
    "    node_to_idx = {node: i for i, node in enumerate(node_set)}\n",
    "\n",
    "    edge_index = torch.tensor([[node_to_idx[o], node_to_idx[d]] for o, d in zip(df['origem'], df['destino'])], dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Edge features\n",
    "    edge_attr = torch.tensor(df_features.values, dtype=torch.float)\n",
    "\n",
    "    # Target edge feature to predict ('espera')\n",
    "    y = torch.tensor(df['espera'].values, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    # Dummy node features (e.g., all ones)\n",
    "    num_nodes = len(node_to_idx)\n",
    "    node_features = torch.ones((num_nodes, 1))  # Dummy node features (1 for each node)\n",
    "\n",
    "    # Create Data object\n",
    "    data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = prepare_data(df)\n",
    "\n",
    "train_mask, test_mask = train_test_split_data(data, test_size=0.2)\n",
    "\n",
    "model = FlightGNNWithGAT(num_features=1, hidden_size=32, target_size=1)\n",
    "criterion = FocalLoss(alpha=0.1, gamma=1000)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, data, train_mask, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {train_loss:.4f}')\n",
    "\n",
    "acc, precision, recall, f1, cm = test(model, data, test_mask)\n",
    "print(f'Test Accuracy: {acc:.4f}')\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{cm}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
