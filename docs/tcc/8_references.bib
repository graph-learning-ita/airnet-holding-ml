@article{defferrard2016convolutional,
  title={Convolutional neural networks on graphs with fast localized spectral filtering},
  author={Defferrard, Micha{\"e}l and Bresson, Xavier and Vandergheynst, Pierre},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}


@article{usgnn,
author = {Chen, Xinye},
year = {2020},
month = {12},
pages = {},
title = {Understanding Spectral Graph Neural Network},
url = {https://arxiv.org/abs/2012.06660}
}

@misc{bo2023surveyspectralgraphneural,
      title={A Survey on Spectral Graph Neural Networks}, 
      author={Deyu Bo and Xiao Wang and Yang Liu and Yuan Fang and Yawen Li and Chuan Shi},
      year={2023},
      eprint={2302.05631},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.05631}, 
}

@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

@article{hamilton2017inductive,
  title={Inductive representation learning on large graphs},
  author={Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{grover2016node2vec,
  title={node2vec: Scalable feature learning for networks},
  author={Grover, Aditya and Leskovec, Jure},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={855--864},
  year={2016}
}

@inproceedings{perozzi2014deepwalk,
  title={Deepwalk: Online learning of social representations},
  author={Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
  booktitle={Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={701--710},
  year={2014}
}

@article{bruna2013spectral,
  title={Spectral networks and locally connected networks on graphs},
  author={Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
  journal={arXiv preprint arXiv:1312.6203},
  year={2013}
}

@article{costa2007characterization,
  title={Characterization of complex networks: A survey of measurements},
  author={Costa, L da F},
  journal={Advances in physics},
  volume={56},
  number={1},
  pages={167--242},
  year={2007},
  publisher={Taylor \& Francis}
}

@article{amanciof,
    doi = {10.1371/journal.pone.0094137},
    author = {Amancio, Diego Raphael AND Comin, Cesar Henrique AND Casanova, Dalcimar AND Travieso, Gonzalo AND Bruno, Odemir Martinez AND Rodrigues, Francisco Aparecido AND da Fontoura Costa, Luciano},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {A Systematic Comparison of Supervised Classifiers},
    year = {2014},
    month = {04},
    volume = {9},
    url = {https://doi.org/10.1371/journal.pone.0094137},
    pages = {1-14},
    abstract = {Pattern recognition has been employed in a myriad of industrial, commercial and academic applications. Many techniques have been devised to tackle such a diversity of applications. Despite the long tradition of pattern recognition research, there is no technique that yields the best classification in all scenarios. Therefore, as many techniques as possible should be considered in high accuracy applications. Typical related works either focus on the performance of a given algorithm or compare various classification methods. In many occasions, however, researchers who are not experts in the field of machine learning have to deal with practical classification tasks without an in-depth knowledge about the underlying parameters. Actually, the adequate choice of classifiers and parameters in such practical circumstances constitutes a long-standing problem and is one of the subjects of the current paper. We carried out a performance study of nine well-known classifiers implemented in the Weka framework and compared the influence of the parameter configurations on the accuracy. The default configuration of parameters in Weka was found to provide near optimal performance for most cases, not including methods such as the support vector machine (SVM). In addition, the k-nearest neighbor method frequently allowed the best accuracy. In certain conditions, it was possible to improve the quality of SVM by more than 20% with respect to their default parameter configuration.},
    number = {4},

}

@article{verri2018advantages,
  title={Advantages of edge-centric collective dynamics in machine learning tasks},
  author={Verri, Filipe Alves Neto and Urio, Paulo Roberto and Zhao, Liang},
  journal={Journal of Applied Nonlinear Dynamics},
  volume={7},
  number={3},
  pages={269--285},
  year={2018},
  publisher={L\&H Scientific Publishing}
}

@article{grape2020,
  title={Handling missing data with graph representation learning},
  author={You, Jiaxuan and Ma, Xiaobai and Ding, Yi and Kochenderfer, Mykel J and Leskovec, Jure},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={19075--19087},
  year={2020}
}
@article{JMLR:Perozzi,
  author  = {Ines Chami and Sami Abu-El-Haija and Bryan Perozzi and Christopher RÃ© and Kevin Murphy},
  title   = {Machine Learning on Graphs: A Model and Comprehensive Taxonomy},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {89},
  pages   = {1--64},
  url     = {http://jmlr.org/papers/v23/20-852.html}
}
@INPROCEEDINGS{verri2013,
  author={Verri, Filipe Alves Neto and Zhao, Liang},
  booktitle={The 2013 International Joint Conference on Neural Networks (IJCNN)}, 
  title={High level data classification based on network entropy}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  keywords={Entropy;Databases;Accuracy;Training;Iris;Pattern formation;Mathematical model},
  doi={10.1109/IJCNN.2013.6707042}}


@book{silva2016machine,
  title={Machine Learning in Complex Networks},
  author={Silva, T.C. and Zhao, L.},
  isbn={9783319172897},
  lccn={2015958893},
  url={https://books.google.com.br/books?id=WdDurQEACAAJ},
  year={2016},
  publisher={Springer International Publishing}
}