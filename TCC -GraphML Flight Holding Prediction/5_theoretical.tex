\chapter[Theoretical Framework]{Theoretical Framework and Related Works}
\label{TheoreticalFramework}

Graph machine learning can be tracked backwards to the problem of `learning' on data that is inherently a graph \cite{silva2016machine, JMLR:Perozzi} or can be modeled as a graph \cite{verri2013,grape2020}. This field encompasses a variety of tasks, including node/edge classification, network construction, link prediction, graph classification, graph cut/partitioning, network embeddings, graph coarsening/reduction, which rely on learning representations from graph-structured data. Over the last decades, researchers have developed numerous approaches to tackle these challenges, initially these techniques were most developed by complex networks researchers. However, in the last decade with the advancements in deep learning, the field has seen a significant shift towards the merging of three main communities: graph signal processing, deep learning and complex nets.

As described, defining the field of graph machine learning is not straightforward, as it encompasses a broad range of methods and applications. The tasks mentioned above are just a few examples of the many challenges that can be addressed through graph-based learning techniques. For clarity, these tasks can be categorized into three main learning paradigms: supervised, unsupervised, and semi-supervised learning. In this study, we are interested on the (semi-)supervised learning paradigm, which encompasses a variety of techniques designed to leverage learning to (partially-)labeled data \cite{verri2018advantages,amanciof}. But we can refine even more, in fact, this work will focus in the subset of graph elements prediction(classification/regression) methods.

In this chapter, we provide an overview of the theoretical framework of graph machine learning for node/edge prediction. Here we consider the division of the field into \texttt{classical} graph learning and \texttt{deep} graph learning, where here `classical' refers to the machine learning techniques applied to graphs before the advent of graph neural networks, where standard ML algorithms were applied to graph data and the topological information measures were encoded as features together with the tabular data  \cite{costa2007characterization, silva2016machine}. This bipartition is what will pave the way of our explanation, since the last decade has seen a complex interplay between these two approaches. The field's evolution can be traced back to when \citeonline{bruna2013spectral} introduced one of the first GNN architectures leaned on the theory of graph signal processing. Concurrently, researchers were developing node embedding techniques like DeepWalk \cite{perozzi2014deepwalk} and node2vec \cite{grover2016node2vec}, which bridged classical and deep approaches while remaining using complex networks concepts. The subsequent years saw a surge in GNN architectures, including Graph Convolutional Networks \cite{kipf2016semi} and GraphSAGE \cite{hamilton2017inductive}, marking a shift towards more sophisticated deep learning approaches for graphs and the unification of the field.  

In the following sections, we explain each subset, their theory and applications, and how they have evolved over time. We also discuss the challenges and limitations of these methods.

\section{Classical graph learning}



These early efforts focused on shallow learning techniques such as feature engineering, graph traversal algorithms, and spectral methods, which laid the foundation for understanding graph structure and dynamics. Methods like community detection, centrality measures, and link prediction became key tools for analyzing large-scale networks in areas such as social science, biology, and infrastructure systems. By modeling relationships as graphs, these approaches enabled researchers to capture both local and global properties, leading to significant insights in network theory and real-world applications.

\section{Deep graph learning}

The rise of deep learning has revolutionized the field of graph machine learning, enabling the development of more powerful and scalable models for graph data. Graph neural networks can be divide in two main categories: spectral-based and spatial-based. Here is a trick thing, the GCN architecture \cite{kipf2016semi} is commonly divulgated as a spatial-based method, since it is more intuitive talking about the convolution operation in the spatial domain, where we simply aggregate information from the immediate neighbors. However, the GCN is a spectral-based method, in fact, it can be thought as a simplification of the first spectral GNN \cite{bruna2013spectral} proposed and that builds the math behind GCNs. That said, first we introduce the spectral-based GNNs and then the spatial-based ones.

\subsection{Spectral-based GNNs}

Spectral methods are rooted in graph signal processing. The core idea is that a signal on a graph can be represented as node features, where each feature vector at a node corresponds to a `signal' defined over the graph. In this context, the graph Laplacian $L = D - A$, where $D$ is the degree matrix and $A$ is the adjacency matrix, plays a crucial role. It captures the structure of the graph and can be used to perform operations analogous to Fourier transforms in classical signal processing. Spectral methods can be categorized into two types: eigenvalue-based, where the focus is on creating a graph filter in the Fourier domain, and eigenvector-based, where the goal is to use a spectral basis to decompose the signal \cite{bo2023surveyspectralgraphneural}.

As we already stated, \citeonline{bruna2013spectral} was the first spectral GNN proposed and the ideia was to translate the ideias from the standard CNN for images to graphs, thats why it's called Spectral CNN (SCNN). The ideia of the SCNN is to use the spectral decomposition of the graph Laplacian $L= U \Lambda U^T $ to define a filter convolution operation in the Fourier domain, where the graph fourier transform in a signal $f$ become $\hat{f}= U^T f$. The convolution operation ($\star$) is defined as $g_{\theta} \star f = U g_{\theta} U^T x$, where $g_{\theta}$ is a learnable filter parameterized by $\theta$, finally the learning in the . The SCNN is a powerful method, but it needs to calculate the entire spectrum of the graph $\mathcal{O}(n^3)$ for a graph, which can be computationally expensive for large graphs.
